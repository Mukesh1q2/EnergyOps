# OptiBid Energy: Kafka Cluster for Market Data Streaming
# Production-ready Apache Kafka deployment with Zookeeper coordination

---
# Zookeeper Cluster (Kafka dependency)
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: zookeeper
  namespace: optibid
  labels:
    app: zookeeper
    component: zookeeper-cluster
spec:
  serviceName: zookeeper
  replicas: 3
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: zookeeper
  template:
    metadata:
      labels:
        app: zookeeper
        component: zookeeper-cluster
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 999
        fsGroup: 999
      containers:
      - name: zookeeper
        image: confluentinc/cp-zookeeper:7.4.0
        ports:
        - containerPort: 2181
          name: client
        - containerPort: 2888
          name: leader
        - containerPort: 3888
          name: follower
        env:
        - name: ZOOKEEPER_CLIENT_PORT
          value: "2181"
        - name: ZOOKEEPER_SERVER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: ZOOKEEPER_SERVERS
          value: "zookeeper-0.zookeeper:2888:3888;zookeeper-1.zookeeper:2888:3888;zookeeper-2.zookeeper:2888:3888"
        - name: ZOOKEEPER_TICK_TIME
          value: "2000"
        - name: ZOOKEEPER_SYNC_LIMIT
          value: "2"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          exec:
            command:
            - sh
            - -c
            - "echo ruok | nc localhost 2181 | grep imok"
          initialDelaySeconds: 30
          periodSeconds: 10
        volumeMounts:
        - name: zookeeper-data
          mountPath: /var/lib/zookeeper/data
        - name: zookeeper-logs
          mountPath: /var/lib/zookeeper/log
  volumeClaimTemplates:
  - metadata:
      name: zookeeper-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
      storageClassName: fast-ssd
  - metadata:
      name: zookeeper-logs
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 5Gi
      storageClassName: fast-ssd

---
# Zookeeper Service
apiVersion: v1
kind: Service
metadata:
  name: zookeeper
  namespace: optibid
  labels:
    app: zookeeper
    component: zookeeper-cluster
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - port: 2181
    targetPort: 2181
    name: client
  - port: 2888
    targetPort: 2888
    name: leader
  - port: 3888
    targetPort: 3888
    name: follower
  selector:
    app: zookeeper

---
# Kafka Brokers StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: optibid
  labels:
    app: kafka
    component: kafka-cluster
spec:
  serviceName: kafka
  replicas: 3
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
        component: kafka-cluster
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1001
        fsGroup: 1001
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:7.4.0
        ports:
        - containerPort: 9092
          name: internal
        - containerPort: 29092
          name: external
        - containerPort: 9091
          name: jmx
        env:
        - name: KAFKA_BROKER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: "zookeeper:2181"
        - name: KAFKA_ADVERTISED_LISTENERS
          value: "PLAINTEXT://kafka-$(KAFKA_BROKER_ID).kafka:9092,PLAINTEXT_HOST://kafka-$(KAFKA_BROKER_ID).kafka:29092"
        - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
          value: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
        - name: KAFKA_INTER_BROKER_LISTENER_NAME
          value: "PLAINTEXT"
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_NUM_PARTITIONS
          value: "12"
        - name: KAFKA_DEFAULT_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_LOG_RETENTION_HOURS
          value: "168"
        - name: KAFKA_LOG_RETENTION_BYTES
          value: "1073741824"
        - name: KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS
          value: "300000"
        - name: KAFKA_LOG_SEGMENT_BYTES
          value: "268435456"
        - name: KAFKA_LOG_ROLL_HOURS
          value: "168"
        - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
          value: "false"
        - name: KAFKA_NUM_PARTITION
          value: "12"
        - name: KAFKA_DEFAULT_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_DELETE_TOPIC_ENABLE
          value: "true"
        - name: KAFKA_JMX_PORT
          value: "9091"
        - name: KAFKA_JMX_HOSTNAME
          value: "localhost"
        - name: KAFKA_JMX_REMOTE_STARTUP_DELAY
          value: "20000"
        - name: KAFKA_HEAP_OPTS
          value: "-Xmx2G -Xms2G"
        - name: KAFKA_OPTS
          value: "-javaagent:/usr/share/jmx_prometheus_javaagent/jmx_prometheus_javaagent-0.17.2.jar=7071:/usr/share/jmx_prometheus_javaagent/config.yml"
        resources:
          requests:
            memory: "3Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
        livenessProbe:
          exec:
            command:
            - sh
            - -c
            - "kafka-topics --bootstrap-server localhost:9092 --list | wc -l"
          initialDelaySeconds: 120
          periodSeconds: 30
          timeoutSeconds: 20
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - "kafka-topics --bootstrap-server localhost:9092 --list"
          initialDelaySeconds: 90
          periodSeconds: 10
          timeoutSeconds: 10
        volumeMounts:
        - name: kafka-data
          mountPath: /var/lib/kafka/data
        - name: kafka-logs
          mountPath: /var/lib/kafka/logs
        - name: jmx-config
          mountPath: /usr/share/jmx_prometheus_javaagent/config.yml
          subPath: config.yml
      volumes:
      - name: jmx-config
        configMap:
          name: kafka-jmx-config
  volumeClaimTemplates:
  - metadata:
      name: kafka-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 50Gi
      storageClassName: fast-ssd
  - metadata:
      name: kafka-logs
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 20Gi
      storageClassName: fast-ssd

---
# Kafka Service
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: optibid
  labels:
    app: kafka
    component: kafka-cluster
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - port: 9092
    targetPort: 9092
    name: internal
  - port: 29092
    targetPort: 29092
    name: external
  - port: 9091
    targetPort: 9091
    name: jmx
  selector:
    app: kafka

---
# Kafka Client Service
apiVersion: v1
kind: Service
metadata:
  name: kafka-cluster
  namespace: optibid
  labels:
    app: kafka
    component: kafka-cluster
    service-type: client
spec:
  type: ClusterIP
  ports:
  - port: 9092
    targetPort: 9092
    name: client
  selector:
    app: kafka

---
# Kafka Topic Management ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-topics-config
  namespace: optibid
  labels:
    app: kafka
data:
  market-data-topics.sh: |
    #!/bin/bash
    set -e
    
    echo "Creating Kafka topics for market data integration..."
    
    # Market data topics
    kafka-topics --create --topic market_data.pjm --bootstrap-server localhost:9092 --partitions 3 --replication-factor 3 --config retention.ms=2592000000
    kafka-topics --create --topic market_data.caiso --bootstrap-server localhost:9092 --partitions 3 --replication-factor 3 --config retention.ms=2592000000
    kafka-topics --create --topic market_data.ercot --bootstrap-server localhost:9092 --partitions 3 --replication-factor 3 --config retention.ms=2592000000
    
    # Processed data topics
    kafka-topics --create --topic market_data.processed --bootstrap-server localhost:9092 --partitions 3 --replication-factor 2 --config retention.ms=604800000
    
    # Metrics and alerts topics
    kafka-topics --create --topic market_metrics --bootstrap-server localhost:9092 --partitions 2 --replication-factor 2 --config retention.ms=2592000000
    kafka-topics --create --topic alerts.market_data --bootstrap-server localhost:9092 --partitions 2 --replication-factor 2 --config retention.ms=604800000
    
    echo "Kafka topics created successfully!"
    
    # List created topics
    kafka-topics --list --bootstrap-server localhost:9092 | grep market

  kafka-topics-init.yaml: |
    apiVersion: batch/v1
    kind: Job
    metadata:
      name: kafka-topics-init
      namespace: optibid
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: kafka-topics-init
            image: confluentinc/cp-kafka:7.4.0
            command: ["/bin/bash"]
            args:
            - "/scripts/market-data-topics.sh"
            volumeMounts:
            - name: scripts
              mountPath: /scripts
          volumes:
          - name: scripts
            configMap:
              name: kafka-topics-config

---
# JMX ConfigMap for Kafka
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-jmx-config
  namespace: optibid
  labels:
    app: kafka
data:
  config.yml: |
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    rules:
    - pattern: kafka.server<type=(.+), name=(.+)PerSec\.(.+), (.+)=(.+)><>Count
      name: kafka_server_$1_$2_total
      type: COUNTER
      labels:
        "$4": "$5"
    - pattern: kafka.server<type=(.+), name=(.+)PerSec\.(.+)><>FiveMinuteRate
      name: kafka_server_$1_$2_rate
      type: GAUGE
    - pattern: kafka.server<type=(.+), (.+)=(.+)><>(Count|Value)
      name: kafka_server_$1_$3
      type: GAUGE

---
# Kafka PersistentVolume for better performance
apiVersion: v1
kind: PersistentVolume
metadata:
  name: kafka-storage
  namespace: optibid
  labels:
    app: kafka
    storage: ssd
spec:
  capacity:
    storage: 200Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: fast-ssd
  hostPath:
    path: /opt/kafka-storage

---
# Kafka Monitoring Service
apiVersion: v1
kind: Service
metadata:
  name: kafka-jmx
  namespace: optibid
  labels:
    app: kafka
    component: monitoring
spec:
  type: ClusterIP
  ports:
  - port: 7071
    targetPort: 7071
    name: jmx-metrics
  selector:
    app: kafka

---
# Kafka Pod Disruption Budget
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: kafka-pdb
  namespace: optibid
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: kafka

---
# Kafka Network Policy
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: kafka-netpol
  namespace: optibid
spec:
  podSelector:
    matchLabels:
      app: kafka
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: optibid-market-data
    - podSelector:
        matchLabels:
          app: optibid-backend
    ports:
    - protocol: TCP
      port: 9092
  - from:
    - podSelector:
        matchLabels:
          app: zookeeper
    ports:
    - protocol: TCP
      port: 9092
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: zookeeper
    ports:
    - protocol: TCP
      port: 2181
  - to: []  # Allow market data API access
    ports:
    - protocol: TCP
      port: 443
    - protocol: TCP
      port: 80

---
# Kafka State Machine
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-manager
  namespace: optibid
  labels:
    app: kafka-manager
    component: kafka-management
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-manager
  template:
    metadata:
      labels:
        app: kafka-manager
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1001
        fsGroup: 1001
      containers:
      - name: kafka-manager
        image: hlebalbau/kafka-manager:3.0.0.5
        ports:
        - containerPort: 9000
          name: ui
        env:
        - name: ZK_HOSTS
          value: "zookeeper:2181"
        - name: APPLICATION_SECRET
          value: "optibid-kafka-secret"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"

---
# Kafka Manager Service
apiVersion: v1
kind: Service
metadata:
  name: kafka-manager
  namespace: optibid
  labels:
    app: kafka-manager
spec:
  type: ClusterIP
  ports:
  - port: 9000
    targetPort: 9000
    name: ui
  selector:
    app: kafka-manager